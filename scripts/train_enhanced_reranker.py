"""Enhanced Training Pipeline for >90% Accuracy with Advanced Features

Uses enhanced 12-feature engineering and optimized hyperparameters to achieve high accuracy.
Includes offline model loading and robust error handling.
"""
from __future__ import annotations

import os
import numpy as np
from typing import List, Dict, Any
from sklearn.metrics import classification_report, f1_score
import xgboost as xgb
import json

# Disable tokenizers parallelism and set offline mode
os.environ['TOKENIZERS_PARALLELISM'] = 'false'
os.environ['TRANSFORMERS_OFFLINE'] = '1'

# Use local database if available, otherwise fallback to mock data
try:
    from src.storage.database import SessionLocal
    from src.embedder.encoder import TransactionEmbedder
    from src.retrieval.service import get_retrieval_service
    from src.reranker.model import Reranker
    from src.utils.logger import get_logger
    HAS_DB = True
except ImportError:
    HAS_DB = False

log = get_logger("enhanced_training") if HAS_DB else None


def load_training_data_from_db(limit: int = 4000) -> List[Dict[str, Any]]:
    """Load training data from database."""
    if not HAS_DB:
        return load_mock_training_data(limit)

    from sqlalchemy import text
    from sqlalchemy.orm import Session

    db = SessionLocal()
    try:
        from src.storage.database import sample_random_examples
        rows = sample_random_examples(db, limit=limit, max_attempts=8)

        examples = []
        for row in rows:
            examples.append({
                'id': row[0],
                'merchant': row[1],
                'amount': float(row[2]) if row[2] else 0.0,
                'description': row[3],
                'category': row[4],
            })

        print(f"Loaded {len(examples)} training examples from database")
        return examples

    finally:
        db.close()


def load_mock_training_data(limit: int = 4000) -> List[Dict[str, Any]]:
    """Fallback mock data for testing without database."""
    categories = ["Food & Dining", "Transportation", "Shopping", "Entertainment",
                 "Bills & Utilities", "Healthcare", "Travel", "Income", "Uncategorized"]

    merchants = {
        "Food & Dining": ["Starbucks", "McDonald's", "Chipotle", "Whole Foods", "Trader Joe's"],
        "Transportation": ["Uber", "Lyft", "Shell", "Chevron", "Metro"],
        "Shopping": ["Amazon", "Target", "Walmart", "Best Buy", "Costco"],
        "Entertainment": ["Netflix", "Spotify", "AMC", "Disney+", "Hulu"],
        "Bills & Utilities": ["PG&E", "Comcast", "AT&T", "Verizon", "Water Company"],
        "Healthcare": ["Kaiser", "Walgreens", "CVS", "Doctor Office", "Pharmacy"],
        "Travel": ["Airbnb", "Hotel", "United Airlines", "Expedia", "Booking.com"],
        "Income": ["Employer", "Payroll", "Freelance", "Investment", "Refund"],
        "Uncategorized": ["Unknown", "Misc", "Other", "Various", "General"]
    }

    examples = []
    for _ in range(limit):
        cat = np.random.choice(categories, p=[0.25, 0.15, 0.2, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05])
        merchant = np.random.choice(merchants[cat])
        amount = np.random.exponential(50) + 5  # Realistic amounts
        examples.append({
            'id': len(examples),
            'merchant': merchant,
            'amount': round(amount, 2),
            'description': f"Transaction at {merchant}",
            'category': cat,
        })

    print(f"Generated {len(examples)} mock training examples")
    return examples


def prepare_training_data(examples: List[Dict[str, Any]], k: int = 30) -> List[Dict[str, Any]]:
    """Prepare training data with retrieval candidates."""
    if HAS_DB:
        embedder = TransactionEmbedder()
        retriever = get_retrieval_service()
    else:
        # Mock embedder and retriever for testing
        class MockEmbedder:
            def encode_transaction(self, merchant, amount, description):
                return np.random.rand(384)  # Mock embedding

        class MockRetriever:
            def retrieve_by_embedding(self, emb, k):
                # Return mock candidates with realistic similarities
                candidates = []
                categories = ["Food & Dining", "Transportation", "Shopping", "Entertainment",
                             "Bills & Utilities", "Healthcare", "Travel", "Income", "Uncategorized"]
                for i in range(k):
                    sim = np.random.beta(2, 5)  # Skewed toward lower similarities
                    cat = np.random.choice(categories)
                    candidates.append({
                        'merchant': f"Mock Merchant {i}",
                        'amount': np.random.exponential(50) + 5,
                        'category': cat,
                        'similarity': sim
                    })
                return candidates

        embedder = MockEmbedder()
        retriever = MockRetriever()

    training_rows = []

    for i, example in enumerate(examples):
        if i % 500 == 0:
            print(f"Processing {i}/{len(examples)} examples")

        # Get embedding
        emb = embedder.encode_transaction(
            example['merchant'], example['amount'], example['description']
        )

        # Get candidates
        candidates = retriever.retrieve_by_embedding(emb, k=k+1)
        candidates = [c for c in candidates if c.get('id') != example.get('id')][:k]

        if candidates:
            training_rows.append({
                'query_text': example['merchant'],
                'candidates': candidates,
                'label': example['category']
            })

    print(f"Prepared {len(training_rows)} training rows with {len(training_rows[0]['candidates'])} candidates each")
    return training_rows


def train_enhanced_reranker():
    """Train reranker with enhanced features and optimized parameters for >90% accuracy."""

    # Load and prepare data
    examples = load_training_data_from_db(4000)
    training_rows = prepare_training_data(examples, k=30)

    # Highly optimized hyperparameters for maximum accuracy
    params = {
        'n_estimators': 1000,
        'max_depth': 8,
        'learning_rate': 0.05,
        'subsample': 0.9,
        'colsample_bytree': 0.9,
        'reg_alpha': 0.1,
        'reg_lambda': 0.5,
        'min_child_weight': 1,
        'gamma': 0.1,
        'objective': 'binary:logistic',
        'eval_metric': 'logloss',
        'n_jobs': -1,
        'random_state': 42,
        'early_stopping_rounds': 50,
    }

    if HAS_DB:
        reranker = Reranker()
        print("Training enhanced reranker with database data...")
    else:
        # Create reranker instance manually for testing
        from src.reranker.model import Reranker
        reranker = Reranker()
        print("Training enhanced reranker with mock data...")

    print(f"Using optimized parameters: n_estimators={params['n_estimators']}, max_depth={params['max_depth']}, learning_rate={params['learning_rate']}")

    reranker.fit_xgb(training_rows, params=params, save=True)

    # Evaluate on training data subset
    print("Evaluating training performance...")

    correct = 0
    total = 0
    category_correct = {}
    category_total = {}

    eval_subset = training_rows[:1000]  # Evaluate on larger subset

    for row in eval_subset:
        category, confidence, _ = reranker.rerank(row['query_text'], row['candidates'])
        predicted = category == row['label']

        if predicted:
            correct += 1
        total += 1

        # Per-category stats
        true_cat = row['label']
        category_total[true_cat] = category_total.get(true_cat, 0) + 1
        if predicted:
            category_correct[true_cat] = category_correct.get(true_cat, 0) + 1

    accuracy = correct / total * 100
    print(".2f")

    # Per-category accuracy
    print("\nPer-category training accuracy:")
    for cat in sorted(category_total.keys()):
        cat_acc = category_correct.get(cat, 0) / category_total[cat] * 100
        print(".1f")

    if accuracy >= 90.0:
        print("\nüéâ SUCCESS: Achieved >90% training accuracy!")
        return True, accuracy
    elif accuracy >= 85.0:
        print("\nüëç GOOD: Achieved >85% training accuracy")
        return True, accuracy
    else:
        print("\n‚ö†Ô∏è  NEEDS IMPROVEMENT: Training accuracy below 85%")
        return False, accuracy


def run_comprehensive_evaluation():
    """Run comprehensive evaluation on the trained model."""
    if not HAS_DB:
        print("Skipping evaluation - no database available")
        return False, 0.0

    try:
        from scripts.evaluate import evaluate

        print("Running comprehensive evaluation...")
        results = evaluate(mode='fusion', limit=1500)

        macro_f1 = results['macro']['f1'] * 100
        micro_f1 = results['micro']['f1'] * 100

        print("\n" + "="*60)
        print("COMPREHENSIVE EVALUATION RESULTS")
        print("="*60)
        print(".2f")
        print(".2f")

        if macro_f1 >= 90.0:
            print("üéâ SUCCESS: Achieved >90% macro F1 accuracy!")
            success = True
        elif macro_f1 >= 85.0:
            print("üëç GOOD: Achieved >85% macro F1 accuracy")
            success = True
        else:
            print("‚ö†Ô∏è  NEEDS IMPROVEMENT: Macro F1 below 85%")
            success = False

        print("\nTop 5 performing categories:")
        sorted_cats = sorted(results['per_class'].items(),
                            key=lambda x: x[1]['f1'], reverse=True)
        for cat, metrics in sorted_cats[:5]:
            f1 = metrics['f1'] * 100
            support = metrics['support']
            print(".1f")

        # Save detailed results
        with open('/home/lathiss/Projects/LumaFin/enhanced_evaluation_results.json', 'w') as f:
            json.dump(results, f, indent=2)

        return success, macro_f1

    except Exception as e:
        print(f"Evaluation failed: {e}")
        return False, 0.0


def main():
    print("üöÄ Enhanced Training Pipeline for >90% Accuracy")
    print("="*55)

    try:
        # Train the model
        train_success, train_accuracy = train_enhanced_reranker()

        # Run comprehensive evaluation
        eval_success, eval_f1 = run_comprehensive_evaluation()

        if eval_success and eval_f1 >= 90.0:
            print("\n‚úÖ ENHANCED TRAINING COMPLETE: Achieved >90% accuracy!")
            print("Model saved and ready for production deployment.")
            return 0
        elif eval_success and eval_f1 >= 85.0:
            print("\n‚úÖ TRAINING COMPLETE: Achieved >85% accuracy")
            print("Model performance is good but may benefit from more training data.")
            return 0
        else:
            print("\n‚ùå Training completed but accuracy target not met.")
            print("Consider increasing training data, adjusting features, or tuning hyperparameters further.")
            return 1

    except Exception as e:
        print(f"\n‚ùå Enhanced training failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())