{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LumaFin - XGBoost Reranker Training\n",
    "\n",
    "This notebook trains the XGBoost reranker model that improves category prediction accuracy.\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Loads training data and fine-tuned embeddings\n",
    "2. Builds FAISS index for retrieval\n",
    "3. Generates training features for reranker\n",
    "4. Trains XGBoost classifier with feature engineering\n",
    "5. Evaluates and saves the trained model\n",
    "\n",
    "**Runtime:** GPU helpful but not required (CPU OK)\n",
    "**Time:** ~15-30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers xgboost faiss-cpu pandas numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "# Load training data\n",
    "train_file = '/content/drive/MyDrive/LumaFin/data/train.csv'\n",
    "test_file = '/content/drive/MyDrive/LumaFin/data/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(f\"‚úÖ Training: {len(df_train)} examples\")\n",
    "print(f\"‚úÖ Test: {len(df_test)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned embedding model (or fallback to base)\n",
    "finetuned_path = '/content/drive/MyDrive/LumaFin/models/lumafin-lacft-v1.0'\n",
    "base_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "if os.path.exists(finetuned_path):\n",
    "    print(f\"‚úÖ Loading fine-tuned model from {finetuned_path}\")\n",
    "    model = SentenceTransformer(finetuned_path)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Fine-tuned model not found, using base model: {base_model_name}\")\n",
    "    model = SentenceTransformer(base_model_name)\n",
    "\n",
    "print(f\"‚úÖ Model loaded. Embedding dim: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create text representations\n",
    "def create_text(row):\n",
    "    desc = row.get('description', '')\n",
    "    return f\"{row['merchant']} {desc} ${row['amount']:.2f}\"\n",
    "\n",
    "print(\"Creating embeddings for FAISS index...\")\n",
    "train_texts = [create_text(row) for _, row in df_train.iterrows()]\n",
    "train_categories = df_train['category'].tolist()\n",
    "\n",
    "# Encode in batches\n",
    "batch_size = 256\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(train_texts), batch_size)):\n",
    "    batch = train_texts[i:i+batch_size]\n",
    "    batch_emb = model.encode(batch, show_progress_bar=False)\n",
    "    embeddings.append(batch_emb)\n",
    "\n",
    "train_embeddings = np.vstack(embeddings).astype('float32')\n",
    "print(f\"‚úÖ Created {len(train_embeddings)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize embeddings for cosine similarity\n",
    "faiss.normalize_L2(train_embeddings)\n",
    "\n",
    "# Build FAISS index\n",
    "dimension = train_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product (cosine after normalization)\n",
    "index.add(train_embeddings)\n",
    "\n",
    "print(f\"‚úÖ FAISS index built with {index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Training Features for Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def extract_reranker_features(query_text, candidates_with_scores, true_category, all_categories):\n",
    "    \"\"\"\n",
    "    Extract features for each candidate category.\n",
    "    Returns a feature matrix and labels.\n",
    "    \"\"\"\n",
    "    # Aggregate scores by category\n",
    "    category_scores = {cat: [] for cat in all_categories}\n",
    "    for cat, score in candidates_with_scores:\n",
    "        category_scores[cat].append(score)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for cat in all_categories:\n",
    "        scores = category_scores[cat]\n",
    "        \n",
    "        # Feature engineering (7 features)\n",
    "        feat = [\n",
    "            len(scores),  # count\n",
    "            sum(scores) if scores else 0,  # sum\n",
    "            max(scores) if scores else 0,  # max\n",
    "            np.mean(scores) if scores else 0,  # mean\n",
    "            min(scores) if scores else 0,  # min\n",
    "            len(scores) / len(candidates_with_scores) if candidates_with_scores else 0,  # vote fraction\n",
    "            0  # amount diff proxy (simplified, set to 0 for now)\n",
    "        ]\n",
    "        features.append(feat)\n",
    "        labels.append(1 if cat == true_category else 0)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "print(\"‚úÖ Feature extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique categories\n",
    "all_categories = sorted(df_train['category'].unique())\n",
    "print(f\"Categories: {all_categories}\")\n",
    "num_categories = len(all_categories)\n",
    "\n",
    "# Use subset for faster training (adjust as needed)\n",
    "train_subset = df_train.sample(n=min(5000, len(df_train)), random_state=42)\n",
    "print(f\"\\n‚úÖ Using {len(train_subset)} examples for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating training features...\")\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "k = 20  # retrieve top-20 candidates\n",
    "\n",
    "for idx, row in tqdm(train_subset.iterrows(), total=len(train_subset)):\n",
    "    query_text = create_text(row)\n",
    "    query_emb = model.encode([query_text])[0].astype('float32')\n",
    "    query_emb = query_emb / np.linalg.norm(query_emb)  # normalize\n",
    "    \n",
    "    # Search FAISS\n",
    "    scores, indices = index.search(np.array([query_emb]), k)\n",
    "    \n",
    "    # Get candidates with scores\n",
    "    candidates = [(train_categories[i], scores[0][j]) for j, i in enumerate(indices[0])]\n",
    "    \n",
    "    # Extract features\n",
    "    X_feat, y_feat = extract_reranker_features(\n",
    "        query_text, candidates, row['category'], all_categories\n",
    "    )\n",
    "    \n",
    "    X_train_list.append(X_feat)\n",
    "    y_train_list.append(y_feat)\n",
    "\n",
    "# Stack all features\n",
    "X_train = np.vstack(X_train_list)\n",
    "y_train = np.hstack(y_train_list)\n",
    "\n",
    "print(f\"\\n‚úÖ Feature matrix: {X_train.shape}\")\n",
    "print(f\"‚úÖ Labels: {y_train.shape}\")\n",
    "print(f\"‚úÖ Positive samples: {y_train.sum()} / {len(y_train)} ({100*y_train.mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.07,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',  # faster training\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost classifier...\")\n",
    "xgb_model = xgb.XGBClassifier(**params)\n",
    "xgb_model.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "print(\"\\n‚úÖ XGBoost training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate probabilities with Platt scaling\n",
    "print(\"Calibrating probabilities...\")\n",
    "calibrated_model = CalibratedClassifierCV(xgb_model, method='sigmoid', cv=3)\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Calibration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(\"Evaluating on test set...\")\n",
    "test_subset = df_test.sample(n=min(1000, len(df_test)), random_state=42)\n",
    "\n",
    "X_test_list = []\n",
    "y_test_list = []\n",
    "test_true_categories = []\n",
    "\n",
    "for idx, row in tqdm(test_subset.iterrows(), total=len(test_subset)):\n",
    "    query_text = create_text(row)\n",
    "    query_emb = model.encode([query_text])[0].astype('float32')\n",
    "    query_emb = query_emb / np.linalg.norm(query_emb)\n",
    "    \n",
    "    scores, indices = index.search(np.array([query_emb]), k)\n",
    "    candidates = [(train_categories[i], scores[0][j]) for j, i in enumerate(indices[0])]\n",
    "    \n",
    "    X_feat, y_feat = extract_reranker_features(\n",
    "        query_text, candidates, row['category'], all_categories\n",
    "    )\n",
    "    \n",
    "    X_test_list.append(X_feat)\n",
    "    y_test_list.append(y_feat)\n",
    "    test_true_categories.append(row['category'])\n",
    "\n",
    "X_test = np.vstack(X_test_list)\n",
    "y_test = np.hstack(y_test_list)\n",
    "\n",
    "print(f\"\\n‚úÖ Test features: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = calibrated_model.predict(X_test)\n",
    "y_pred_proba = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"\\n‚úÖ F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category-level accuracy\n",
    "print(\"\\nüìä Category-Level Performance:\")\n",
    "correct = 0\n",
    "total = len(test_subset)\n",
    "\n",
    "for i, row in enumerate(test_subset.iterrows()):\n",
    "    idx, data = row\n",
    "    true_cat = data['category']\n",
    "    \n",
    "    # Get predictions for this example\n",
    "    start_idx = i * num_categories\n",
    "    end_idx = start_idx + num_categories\n",
    "    example_probs = y_pred_proba[start_idx:end_idx]\n",
    "    \n",
    "    # Predicted category\n",
    "    pred_idx = np.argmax(example_probs)\n",
    "    pred_cat = all_categories[pred_idx]\n",
    "    \n",
    "    if pred_cat == true_cat:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"\\n‚úÖ Reranker Accuracy: {accuracy:.1%} ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to Google Drive\n",
    "model_path = '/content/drive/MyDrive/LumaFin/models/xgb_reranker.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(calibrated_model, f)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "\n",
    "# Also save as XGBoost JSON format\n",
    "xgb_path = '/content/drive/MyDrive/LumaFin/models/xgb_reranker.json'\n",
    "xgb_model.save_model(xgb_path)\n",
    "print(f\"‚úÖ XGBoost model saved to: {xgb_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index and metadata\n",
    "faiss_path = '/content/drive/MyDrive/LumaFin/models/faiss_index.bin'\n",
    "metadata_path = '/content/drive/MyDrive/LumaFin/models/faiss_metadata.pkl'\n",
    "\n",
    "faiss.write_index(index, faiss_path)\n",
    "print(f\"‚úÖ FAISS index saved to: {faiss_path}\")\n",
    "\n",
    "metadata = {\n",
    "    'categories': train_categories,\n",
    "    'texts': train_texts,\n",
    "    'all_categories': all_categories\n",
    "}\n",
    "\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(f\"‚úÖ Metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete!\n",
    "\n",
    "Your XGBoost reranker and FAISS index are ready!\n",
    "\n",
    "**Saved files:**\n",
    "- `xgb_reranker.pkl` - Calibrated XGBoost classifier\n",
    "- `xgb_reranker.json` - XGBoost model in JSON format\n",
    "- `faiss_index.bin` - FAISS vector index\n",
    "- `faiss_metadata.pkl` - Category and text metadata\n",
    "\n",
    "### Next Steps:\n",
    "1. **Run notebook 04_evaluate_pipeline.ipynb** to evaluate the complete system\n",
    "\n",
    "### To use these models in your local repository:\n",
    "1. Download all files from `/content/drive/MyDrive/LumaFin/models/`\n",
    "2. Place them in your local `models/` directory\n",
    "3. Update `.env` file with appropriate paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
